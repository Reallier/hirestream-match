# -*- coding: utf-8 -*-
import os
import uuid
import time
import streamlit as st
from dotenv import load_dotenv
import toml # Import toml library

from match_engine import extract_text_from_upload, call_qwen_json
from utils import hash_inputs, render_markdown_report
from log import logger as log
from token_calculator import TokenCalculator
from pricing_config import get_model_display_name


# -------- Env --------
load_dotenv()
USER_TEMPLATE = os.getenv("USER_TEMPLATE")
QWEN_MODEL = os.getenv("QWEN_MODEL")


# -------- Page --------
st.set_page_config(page_title="HireStream Match â€” ç®€å†ä¸JDæ™ºèƒ½åŒ¹é…", page_icon="ğŸ§²", layout="centered")
st.caption("æç¤ºï¼šç²˜è´´JD + ä¸Šä¼ ç®€å†åï¼Œä¼šè‡ªåŠ¨åˆ†æï¼Œæ— éœ€ç‚¹å‡»æŒ‰é’®ã€‚")

# --- JD Block ---
with st.container(border=True):
    jd_text = st.text_area(
        "èŒä½æè¿°ï¼ˆJDï¼‰",
        height=220,
        placeholder="åœ¨æ­¤ç²˜è´´JDæ–‡æœ¬â€¦â€¦",
        key="jd_text"
    )

    # è‹¥å†…å®¹éç©ºä¸”åˆšåˆšå˜åŒ–ï¼Œåˆ™è‡ªåŠ¨å¤„ç†
    if jd_text and st.session_state.get("jd_last") != jd_text:
        st.session_state["jd_last"] = jd_text
        st.toast("âœ… JD å·²è‡ªåŠ¨æ›´æ–°ï¼")  # å³ä¸Šè§’å¼¹å‡ºæç¤ºæ¡†ï¼ˆè‡ªåŠ¨æ¶ˆå¤±ï¼‰

# --- Resume Block ---
resume_text = ""
with st.container(border=True):
    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    up = st.file_uploader(
        "ä¸Šä¼ å€™é€‰äººç®€å†ï¼ˆPDF æˆ– å›¾ç‰‡æ ¼å¼ â‰¤ 2MBï¼‰",
        type=["pdf", "jpg", "jpeg", "png", "gif", "bmp", "webp"],
        accept_multiple_files=False,
        key="resume_file",
        help="æ”¯æŒ PDF å’Œå¸¸è§å›¾ç‰‡æ ¼å¼ï¼ˆJPG/PNG/GIF/BMP/WEBPï¼‰"
    )

    # æ·»åŠ åˆ†å‰²çº¿
    st.markdown("---")

    # æ–‡æœ¬è¾“å…¥æ¡†
    resume_text_input = st.text_area(
        "æˆ–åœ¨æ­¤ç²˜è´´ç®€å†æ–‡æœ¬",
        height=220,
        placeholder="åœ¨æ­¤ç²˜è´´ç®€å†æ–‡æœ¬â€¦â€¦",
        key="resume_text"
    )

    # è‹¥æ–‡æœ¬å†…å®¹éç©ºä¸”åˆšåˆšå˜åŒ–ï¼Œåˆ™è‡ªåŠ¨å¤„ç†
    if resume_text_input and st.session_state.get("resume_text_last") != resume_text_input:
        st.session_state["resume_text_last"] = resume_text_input
        st.toast("âœ… ç®€å†æ–‡æœ¬å·²è‡ªåŠ¨æ›´æ–°ï¼")  # å³ä¸Šè§’å¼¹å‡ºæç¤ºæ¡†ï¼ˆè‡ªåŠ¨æ¶ˆå¤±ï¼‰

    # å¤„ç†ç®€å†å†…å®¹è·å–é€»è¾‘
    # ä¼˜å…ˆä½¿ç”¨æ–‡æœ¬è¾“å…¥ï¼Œå…¶æ¬¡ä½¿ç”¨æ–‡ä»¶ä¸Šä¼ 
    if resume_text_input.strip():
        resume_text = resume_text_input.strip()
        st.session_state["ocr_usage"] = None  # æ–‡æœ¬è¾“å…¥ä¸éœ€è¦ OCR
    elif up is not None:
        log.info("upload_received | name={} size={}", up.name, up.size)
        with st.status("æ­£åœ¨è¯†åˆ«â€¦", expanded=True) as status:
            if up.size > 2 * 1024 * 1024:
                status.update(label="æ–‡ä»¶è¿‡å¤§", state="error")
                st.error("æ–‡ä»¶è¿‡å¤§ï¼šéœ€ â‰¤ 2MBã€‚")
                log.warning("upload_rejected | reason=file_too_large | size={}", up.size)
            else:
                try:
                    resume_text, ocr_usage = extract_text_from_upload(up.name, up.read())
                    # è®¡ç®— OCR è´¹ç”¨
                    ocr_prompt = ocr_usage.get("prompt_tokens", 0)
                    ocr_completion = ocr_usage.get("completion_tokens", 0)
                    ocr_model = ocr_usage.get("model", "qwen-vl-ocr-2025-11-20")
                    ocr_cost = TokenCalculator.calculate_cost(ocr_model, ocr_prompt, ocr_completion)
                    ocr_usage["cost"] = ocr_cost
                    st.session_state["ocr_usage"] = ocr_usage
                    log.info("ocr_completed | model={} tokens={} cost={}", ocr_model, ocr_prompt + ocr_completion, ocr_cost)
                except Exception as e:
                    status.update(label="è§£æå¤±è´¥", state="error")
                    st.error(f"è§£æå¤±è´¥ï¼š{e}")
                else:
                    status.update(label="å®Œæˆ âœ…", state="complete")
                    st.success(f"æ–‡ä»¶å·²ä¸Šä¼ å¹¶è§£æå®Œæˆï¼š{up.name}")
                    st.text(resume_text[:500] + ("â€¦" if len(resume_text) > 500 else ""))  # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦


# --- Analyze Block ---
placeholder = st.container(border=True)  # åˆ›å»ºä¸€ä¸ªå¸¦è¾¹æ¡†çš„å®¹å™¨ï¼Œç”¨äºæ˜¾ç¤ºåŒ¹é…ç»“æœéƒ¨åˆ†
with placeholder:  # åœ¨è¯¥å®¹å™¨ä¸­ç»˜åˆ¶å†…å®¹
    st.markdown("### åŒ¹é…ç»“æœ")
    # ä»…å½“èŒä½æè¿°å’Œç®€å†æ–‡æœ¬éƒ½å­˜åœ¨ä¸”éç©ºæ—¶æ‰æ‰§è¡Œåˆ†æé€»è¾‘
    if jd_text and resume_text:
        # è®¡ç®—ä¸¤æ®µæ–‡æœ¬çš„å“ˆå¸Œå€¼ï¼Œç”¨äºåˆ¤æ–­å†…å®¹æ˜¯å¦å˜åŒ–ï¼ˆé˜²æŠ–ï¼‰
        key = hash_inputs(jd_text, resume_text)
        cache_hit = st.session_state.get("last_key") == key and st.session_state.get("result") is not None
        log.info("analyze_trigger | cache_hit={}", cache_hit)

        if not cache_hit:
            st.session_state["last_key"] = key  # æ›´æ–° session_state ä¸­è®°å½•çš„å“ˆå¸Œå€¼
            st.session_state["result"] = None  # æ¸…ç©ºæ—§çš„åˆ†æç»“æœ
            with st.spinner("æ­£åœ¨åˆ†æåŒ¹é…åº¦â€¦"):  # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»æç¤ºç”¨æˆ·æ¨¡å‹æ­£åœ¨è¿è¡Œ
                t0 = time.perf_counter()
                try:
                    # æ„é€ ç”¨æˆ·æç¤ºè¯ï¼ˆå°†JDå’Œç®€å†å†…å®¹å¡«å…¥æ¨¡æ¿ï¼‰
                    log.info("11111111111111model_request | model={} user_prompt={}", QWEN_MODEL, USER_TEMPLATE)
                    user_prompt = USER_TEMPLATE.format(job_description=jd_text.strip(), resume_content=resume_text.strip())
                    # è°ƒç”¨åƒé—®æ¨¡å‹APIè¿›è¡ŒåŒ¹é…åº¦åˆ†æ
                    result = call_qwen_json(user_prompt=user_prompt)
                    st.session_state["result"] = result
                    score = int(result.get("match_score", 0))
                    ms = int((time.perf_counter() - t0) * 1000)
                    token_usage = result.get("token_usage", {})
                    log.info("model_ok | model={} score={} ms={} token_usage={}", QWEN_MODEL, score, ms, token_usage)
                except Exception as e:
                    log.exception("model_failed | model={}", QWEN_MODEL)
                    st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼š{e}")
                    st.stop()

        # Render report if available
        result = st.session_state.get("result")  # ä» session_state è¯»å–å½“å‰åˆ†æç»“æœ
        if result:  # å¦‚æœç»“æœå­˜åœ¨ï¼Œæ‰§è¡Œå±•ç¤ºé€»è¾‘
            # Visual score meter
            score = int(result.get("match_score", 0))  # è·å–åŒ¹é…å¾—åˆ†ï¼ˆé»˜è®¤0ï¼‰
            st.progress(score/100.0, text=f"åŒ¹é…åº¦ {score}%")  # ç»˜åˆ¶è¿›åº¦æ¡å½¢å¼çš„åŒ¹é…åº¦æŒ‡ç¤ºå™¨
            st.markdown(render_markdown_report(result), unsafe_allow_html=False)  # æ¸²æŸ“æŠ¥å‘Šçš„ Markdown å†…å®¹

            token_usage = result.get("token_usage", {})

# Get version from pyproject.toml
try:
    with open("pyproject.toml", "r", encoding="utf-8") as f:
        pyproject_data = toml.load(f)
    __version__ = pyproject_data["project"]["version"]
except Exception:
    __version__ = "N/A"


# --- Resource Consumption Block ---
if st.session_state.get("result"):
    analysis_usage = st.session_state["result"].get("token_usage", {})
    ocr_usage = st.session_state.get("ocr_usage", {})
    
    # åªæœ‰å½“æœ‰ token ä½¿ç”¨æ•°æ®æ—¶æ‰æ˜¾ç¤º
    if analysis_usage or ocr_usage:
        with st.container(border=True):
            st.markdown("### ğŸ’° è´¹ç”¨æ˜ç»†")
            
            # è®¡ç®—å„é¡¹è´¹ç”¨
            total_cost = 0.0
            
            # OCR è´¹ç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if ocr_usage:
                ocr_prompt = ocr_usage.get("prompt_tokens", 0)
                ocr_completion = ocr_usage.get("completion_tokens", 0)
                ocr_total = ocr_prompt + ocr_completion
                ocr_cost = ocr_usage.get("cost", 0)
                ocr_model = ocr_usage.get("model", "qwen-vl-ocr-2025-11-20")
                ocr_pages = ocr_usage.get("pages", 1)
                total_cost += ocr_cost
                
                st.markdown(f"""
**ğŸ” OCR è¯†åˆ«** ({get_model_display_name(ocr_model)})
- é¡µæ•°: {ocr_pages}
- Token: è¾“å…¥ {ocr_prompt:,} + è¾“å‡º {ocr_completion:,} = **{ocr_total:,}**
- è´¹ç”¨: **Â¥{ocr_cost:.6f}**
""")
            
            # åˆ†æè´¹ç”¨
            if analysis_usage:
                analysis_prompt = analysis_usage.get("prompt_tokens", 0)
                analysis_completion = analysis_usage.get("completion_tokens", 0)
                analysis_total = analysis_usage.get("total_tokens", analysis_prompt + analysis_completion)
                analysis_cost = analysis_usage.get("cost", 0)
                analysis_model = analysis_usage.get("model", QWEN_MODEL)
                total_cost += analysis_cost
                
                # æ˜¾ç¤ºé˜¶æ¢¯ä¿¡æ¯
                tier_info = ""
                if analysis_prompt <= 32000:
                    tier_info = "â‰¤32k"
                elif analysis_prompt <= 128000:
                    tier_info = "32k~128k"
                else:
                    tier_info = "128k~256k"
                
                st.markdown(f"""
**ğŸ“Š åŒ¹é…åˆ†æ** ({get_model_display_name(analysis_model)})
- é˜¶æ¢¯: {tier_info}
- Token: è¾“å…¥ {analysis_prompt:,} + è¾“å‡º {analysis_completion:,} = **{analysis_total:,}**
- è´¹ç”¨: **Â¥{analysis_cost:.6f}**
""")
            
            # æ€»è®¡
            st.markdown("---")
            st.markdown(f"**ğŸ“ˆ æ€»è´¹ç”¨: Â¥{total_cost:.6f}**")

st.caption(f"Â© 2025 HireStream Match v{__version__} Â· Powered by Qwen-3 Max")

st.markdown("""
<style>
header[data-testid="stHeader"]{display:none;}
/* æŠŠè§†å›¾å®¹å™¨çš„é¡¶è¾¹è·æ¸…é›¶ï¼ˆè¦†ç›– header é¢„ç•™çš„ offsetï¼‰*/
div[data-testid="stAppViewContainer"]{padding-top:0 !important;}
/* æ”¶ç´§é¦–ä¸ªåŒºå—ä¸ H1 çš„è·ç¦» */
div.block-container{padding-top:1rem;}
h1:first-child{margin-top:0;}
#MainMenu, footer{display:none;}
</style>
""", unsafe_allow_html=True)