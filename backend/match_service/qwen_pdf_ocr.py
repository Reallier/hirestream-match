# -*- coding: utf-8 -*-
"""
Qwen PDF OCR å°è£…ç±»ï¼ˆæ”¯æŒ pdf_path æˆ– pdf_bytesï¼‰
ä¾èµ–ï¼špip install pymupdf pillow dashscope
"""

import os, io, base64, json, traceback, tempfile, sys
import fitz
from PIL import Image
from log import logger
import dashscope


class QwenPDFOCR:
    # ä¼˜åŒ–æç¤ºè¯ï¼šæ˜Žç¡®è¦æ±‚è¿”å›žçº¯æ–‡æœ¬ï¼Œä¸è¦åæ ‡/è¾¹ç•Œæ¡†æ ¼å¼
    DEFAULT_HINT = (
        "è¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œç›´æŽ¥è¾“å‡ºçº¯æ–‡æœ¬ã€‚"
        "è¦æ±‚ï¼š1. åªè¾“å‡ºæ–‡å­—å†…å®¹ï¼Œä¸è¦è¾“å‡ºåæ ‡ã€è¾¹ç•Œæ¡†æˆ–ä½ç½®ä¿¡æ¯ï¼›"
        "2. æŒ‰ä»Žä¸Šåˆ°ä¸‹ã€ä»Žå·¦åˆ°å³çš„é˜…è¯»é¡ºåºè¾“å‡ºï¼›"
        "3. ä¿ç•™æ®µè½æ¢è¡Œå’Œé¡¹ç›®ç¬¦å·ï¼›"
        "4. ä¸è¦æ€»ç»“æˆ–æ”¹å†™åŽŸæ–‡ï¼›"
        "5. æ— æ³•è¯†åˆ«çš„æ–‡å­—ç”¨ [?] æ ‡è®°ã€‚"
    )

    def __init__(
        self,
        pdf_path: str | None = None,
        pdf_bytes: bytes | None = None,
        api_key: str = "",
        model: str = "qwen-vl-ocr-2025-11-20",
        region: str = "cn",   # "cn" å›½å†…ï¼›"intl" å›½é™…
        dpi: int = 400,
        ocr_hint: str | None = None,
        timeout: tuple[int, int] = (8, 120),
        verbose: bool = True,
    ):
        """
        :param pdf_path: PDF æ–‡ä»¶è·¯å¾„ï¼ˆäºŒé€‰ä¸€ï¼‰
        :param pdf_bytes: PDF çš„åŽŸå§‹å­—èŠ‚å†…å®¹ï¼ˆäºŒé€‰ä¸€ï¼‰
        :param api_key: DashScope API Key
        :param model:   æ¨¡åž‹åç§°ï¼Œé»˜è®¤ qwen-vl-ocr
        :param region:  "cn" æˆ– "intl"
        :param dpi:     æ¸²æŸ“ PDF ä½å›¾ DPI
        :param ocr_hint:ä¼ ç»™æ¨¡åž‹çš„æŒ‡ä»¤
        :param timeout:(connect_timeout, read_timeout)
        :param verbose:æ‰“å°è¯¦ç»†æ—¥å¿—
        """
        self.pdf_path = pdf_path
        self.pdf_bytes = pdf_bytes

        self.api_key = api_key
        self.model = model
        self.region = region
        self.dpi = dpi
        self.ocr_hint = ocr_hint or self.DEFAULT_HINT
        self.timeout = timeout
        self.verbose = verbose

        # æ¸…ç†ä»£ç†ï¼Œè®¾ç½®åœ°åŒº base_url
        for k in ("HTTPS_PROXY", "HTTP_PROXY", "ALL_PROXY", "REQUESTS_CA_BUNDLE"):
            os.environ.pop(k, None)
        self._set_base_url(self.region)

    # ------------------ ä¾¿æ·æž„é€  ------------------
    @staticmethod
    def from_bytes(
        data: bytes,
        api_key: str,
        model: str = "qwen-vl-ocr-2025-11-20",
        region: str = "cn",
        dpi: int = 400,
        ocr_hint: str | None = None,
        timeout: tuple[int, int] = (8, 120),
        verbose: bool = True,
    ) -> "QwenPDFOCR":
        return QwenPDFOCR(
            pdf_path=None,
            pdf_bytes=data,
            api_key=api_key,
            model=model,
            region=region,
            dpi=dpi,
            ocr_hint=ocr_hint,
            timeout=timeout,
            verbose=verbose,
        )

    @staticmethod
    def from_image_bytes(
        data: bytes,
        api_key: str,
        model: str = "qwen-vl-ocr-2025-11-20",
        region: str = "cn",
        ocr_hint: str | None = None,
        timeout: tuple[int, int] = (8, 120),
        verbose: bool = True,
    ) -> tuple[str, dict]:
        """
        ç›´æŽ¥å¤„ç†å•å¼ å›¾ç‰‡çš„OCRï¼ˆä¸åˆ›å»ºå®žä¾‹ï¼Œç›´æŽ¥è¿”å›žæ–‡æœ¬å’Œtokenä½¿ç”¨é‡ï¼‰
        :param data: å›¾ç‰‡çš„å­—èŠ‚å†…å®¹
        :param api_key: DashScope API Key
        :param model: æ¨¡åž‹åç§°
        :param region: "cn" æˆ– "intl"
        :param ocr_hint: OCRæç¤ºè¯
        :param timeout: è¶…æ—¶è®¾ç½®
        :param verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        :return: (OCRè¯†åˆ«çš„æ–‡æœ¬, tokenä½¿ç”¨é‡å­—å…¸)
        """
        instance = QwenPDFOCR(
            pdf_path=None,
            pdf_bytes=None,
            api_key=api_key,
            model=model,
            region=region,
            dpi=400,
            ocr_hint=ocr_hint,
            timeout=timeout,
            verbose=verbose,
        )
        return instance._ocr_one_image(data)

    # ------------------ å·¥å…·æ–¹æ³• ------------------

    @staticmethod
    def _set_base_url(region: str):
        dashscope.base_http_api_url = (
            "https://dashscope.aliyuncs.com/api/v1"
            if region == "cn"
            else "https://dashscope-intl.aliyuncs.com/api/v1"
        )

    @staticmethod
    def _pil_to_jpeg_bytes(img: Image.Image, quality=85) -> bytes:
        buf = io.BytesIO()
        img.convert("RGB").save(buf, format="JPEG", quality=quality, optimize=True)
        return buf.getvalue()

    @staticmethod
    def _pix_to_pil(pix: fitz.Pixmap) -> Image.Image:
        return Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

    def _call_qwen(self, messages) -> tuple:
        """è°ƒç”¨ Qwen API å¹¶è¿”å›žå“åº”å’Œ token ä½¿ç”¨é‡"""
        from dashscope import MultiModalConversation
        resp = MultiModalConversation.call(
            api_key=self.api_key,
            model=self.model,
            messages=messages,
            stream=False,
            timeout=self.timeout,
        )
        
        # æå– token ä½¿ç”¨é‡
        token_usage = {"prompt_tokens": 0, "completion_tokens": 0}
        try:
            usage = getattr(resp, "usage", None)
            if usage:
                token_usage["prompt_tokens"] = getattr(usage, "input_tokens", 0) or 0
                token_usage["completion_tokens"] = getattr(usage, "output_tokens", 0) or 0
        except Exception:
            pass
        
        return resp, token_usage

    # ------------------ åæ ‡æ ¼å¼åŽå¤„ç† ------------------

    @staticmethod
    def _extract_text_from_coordinate_format(text: str) -> str | None:
        """
        å°è¯•ä»Žåæ ‡æ ¼å¼ä¸­æå–çº¯æ–‡æœ¬ã€‚
        æ ¼å¼ç¤ºä¾‹: "100,32,23,33,90,è‡ª" -> "è‡ª"
        æˆ–: "164,30,25,129,90,é¡¹ç›®ç»åŽ†" -> "é¡¹ç›®ç»åŽ†"
        """
        if not text:
            return None
        
        lines = text.strip().split("\n")
        extracted = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æµ‹æ˜¯å¦æ˜¯åæ ‡æ ¼å¼ (è‡³å°‘æœ‰4ä¸ªé€—å·åˆ†éš”çš„æ•°å­—å¼€å¤´)
            parts = line.split(",")
            if len(parts) >= 5:
                # æ£€æŸ¥å‰å‡ ä¸ªéƒ¨åˆ†æ˜¯å¦éƒ½æ˜¯æ•°å­—
                try:
                    # æ£€æŸ¥å‰4ä¸ªæ˜¯å¦æ˜¯æ•°å­—ï¼ˆåæ ‡ï¼‰
                    is_coord_format = all(p.strip().isdigit() for p in parts[:4])
                    if is_coord_format:
                        # æœ€åŽä¸€ä¸ªéƒ¨åˆ†æ˜¯æ–‡æœ¬
                        text_part = ",".join(parts[5:]) if len(parts) > 5 else (parts[-1] if not parts[-1].strip().isdigit() else "")
                        if text_part and not text_part.strip().isdigit():
                            extracted.append(text_part.strip())
                        continue
                except:
                    pass
            
            # ä¸æ˜¯åæ ‡æ ¼å¼ï¼Œä¿ç•™åŽŸæ–‡
            extracted.append(line)
        
        if extracted:
            result = "\n".join(extracted)
            if len(result) > 10:  # è‡³å°‘æœ‰ä¸€äº›æœ‰æ„ä¹‰çš„æ–‡æœ¬
                return result
        return None

    # ------------------ å“åº”è§£æž ------------------

    def _parse_resp(self, resp):
        """ç¨³å¥è§£æž Qwen å¤šæ¨¡æ€è¿”å›ž - å¢žå¼ºç‰ˆ"""
        # è®°å½•çŠ¶æ€ç ç­‰å…ƒä¿¡æ¯
        for k in ("status_code", "code", "message"):
            v = getattr(resp, k, None)
            if v is not None:
                logger.info(f"    {k} = {v}")

        out = getattr(resp, "output", {}) or {}
        logger.info(f">>> resp.output keys: {list(out.keys()) if isinstance(out, dict) else type(out)}")

        # æ–¹æ¡ˆ1: æ ‡å‡† choices æ ¼å¼
        choices = out.get("choices") or out.get("outputs") or []
        if choices:
            msg = choices[0].get("message") or choices[0].get("messages", [{}])[0]
            content = msg.get("content", [])
            logger.info(f">>> choices[0].content ç±»åž‹: {type(content)}")
            
            if isinstance(content, list):
                texts = []
                for c in content:
                    if isinstance(c, dict):
                        # æ ‡å‡† text å­—æ®µ
                        if "text" in c:
                            texts.append(c["text"])
                        # æŸäº›ç‰ˆæœ¬è¿”å›ž box æ ¼å¼: {"box": [x,y,w,h], "text": "å†…å®¹"}
                        elif "box" in c and isinstance(c.get("box"), list):
                            # æœ‰äº›å“åº”æŠŠæ–‡æœ¬æ”¾åœ¨å…¶ä»–å­—æ®µ
                            box_text = c.get("text") or c.get("content") or c.get("label") or ""
                            if box_text:
                                texts.append(str(box_text))
                    elif isinstance(c, str) and c.strip():
                        texts.append(c)
                
                text = "\n".join([t for t in texts if t]).strip()
                if text:
                    logger.info(f">>> ä»Ž choices è§£æžæˆåŠŸï¼Œé•¿åº¦: {len(text)}")
                    return text
            elif isinstance(content, str) and content.strip():
                return content.strip()

        # æ–¹æ¡ˆ2: output_text å±žæ€§
        ot = None
        try:
            ot = getattr(resp, "output_text", None)
        except Exception:
            ot = None
        if ot:
            logger.info(">>> ä½¿ç”¨ resp.output_text è§£æžæˆåŠŸ")
            return str(ot).strip()

        # æ–¹æ¡ˆ3: å°è¯•ä»ŽåŽŸå§‹ dict æå–
        try:
            raw = resp.to_dict() if hasattr(resp, "to_dict") else getattr(resp, "__dict__", {})
            
            # æ·±åº¦æœç´¢ text å­—æ®µ
            def find_text_deep(obj, depth=0):
                if depth > 5:
                    return []
                texts = []
                if isinstance(obj, dict):
                    # ç›´æŽ¥çš„ text å­—æ®µ
                    if "text" in obj and isinstance(obj["text"], str):
                        texts.append(obj["text"])
                    # éåŽ†æ‰€æœ‰å€¼
                    for v in obj.values():
                        texts.extend(find_text_deep(v, depth + 1))
                elif isinstance(obj, list):
                    for item in obj:
                        texts.extend(find_text_deep(item, depth + 1))
                return texts
            
            found_texts = find_text_deep(raw)
            if found_texts:
                combined = "\n".join([t for t in found_texts if t and len(t) > 2])
                if combined and len(combined) > 10:
                    logger.info(f">>> æ·±åº¦æœç´¢è§£æžæˆåŠŸï¼Œæ‰¾åˆ° {len(found_texts)} æ®µæ–‡æœ¬")
                    return combined
            
            # ä»…è®°å½•å…ƒä¿¡æ¯ï¼Œä¸è®°å½•åŽŸå§‹å“åº”å†…å®¹ï¼ˆé˜²æ­¢ç®€åŽ†éšç§æ³„éœ²åˆ°æ—¥å¿—ï¼‰
            raw_keys = list(raw.keys()) if isinstance(raw, dict) else str(type(raw))
            logger.warning(f">>> OCR è§£æžå¤±è´¥ | å“åº”ç»“æž„: {raw_keys} | è¯·æ£€æŸ¥ API è¿”å›žæ ¼å¼")
        except Exception as e:
            logger.warning(f">>> æ— æ³•åºåˆ—åŒ– resp: {e}")

        return None

    # ------------------ å…³é”® OCR é€»è¾‘ ------------------

    def _ocr_one_image(self, img_bytes: bytes) -> tuple[str, dict]:
        """
        ä¸Šä¼ ç­–ç•¥ï¼š
          1) data:url ç›´æŽ¥ä¼  {"image": data_url}
          2) è‹¥ SDK ä¸æ”¯æŒï¼Œåˆ™è½ç›˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œæ”¹ç”¨ {"image": "file://..."}
        
        Returns:
            (text, token_usage) - OCRæ–‡æœ¬å’Œtokenä½¿ç”¨é‡
        """
        token_usage = {"prompt_tokens": 0, "completion_tokens": 0, "model": self.model}
        
        # æ–¹æ¡ˆ1ï¼šdata URL
        try:
            b64 = base64.b64encode(img_bytes).decode("ascii")
            data_url = f"data:image/jpeg;base64,{b64}"
            msgs = [{"role": "user", "content": [{"text": self.ocr_hint}, {"image": data_url}]}]
            logger.info(">>> å°è¯•æ–¹æ¡ˆ1: data:url")
            resp, usage = self._call_qwen(msgs)
            token_usage["prompt_tokens"] = usage.get("prompt_tokens", 0)
            token_usage["completion_tokens"] = usage.get("completion_tokens", 0)
            text = self._parse_resp(resp)
            if text:
                return text, token_usage
            else:
                logger.info(">>> æ–¹æ¡ˆ1è¿”å›žä¸å¯è§£æžæ–‡æœ¬ï¼Œåˆ‡æ¢åˆ°æ–¹æ¡ˆ2")
        except Exception as e:
            logger.info("âŒ æ–¹æ¡ˆ1è°ƒç”¨å¼‚å¸¸:", e)
            traceback.print_exc()
            logger.info(">>> åˆ‡æ¢åˆ°æ–¹æ¡ˆ2")

        # æ–¹æ¡ˆ2ï¼šè½ç›˜ file://
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as f:
                f.write(img_bytes)
                tmp_path = f.name
            file_url = f"file://{tmp_path.replace(os.sep, '/')}"
            msgs = [{"role": "user", "content": [{"text": self.ocr_hint}, {"image": file_url}]}]
            logger.info(">>> å°è¯•æ–¹æ¡ˆ2: file:// ä¸Šä¼ ", file_url)
            resp, usage = self._call_qwen(msgs)
            token_usage["prompt_tokens"] += usage.get("prompt_tokens", 0)
            token_usage["completion_tokens"] += usage.get("completion_tokens", 0)
            text = self._parse_resp(resp)
            return (text or "[OCR å¤±è´¥: æ— æ³•ä»Žå“åº”ä¸­è§£æžæ–‡æœ¬]"), token_usage
        except Exception as e:
            logger.info("âŒ æ–¹æ¡ˆ2è°ƒç”¨å¼‚å¸¸:", e)
            traceback.print_exc()
            return f"[APIè°ƒç”¨å¤±è´¥: {e}]", token_usage
        finally:
            try:
                if tmp_path and os.path.exists(tmp_path):
                    os.remove(tmp_path)
            except Exception:
                pass



    # ------------------ å¯¹å¤–ä¸»æµç¨‹ ------------------

    def run(self, max_workers: int = 10) -> tuple[str, dict]:
        """
        ã€ä¼˜åŒ–ç‰ˆã€‘æ‰§è¡Œ PDF å…¨é‡ OCRï¼Œå¹¶å‘å¤„ç†é¡µé¢ä»¥æé«˜é€Ÿåº¦ã€‚
        :param max_workers: å¹¶å‘çº¿ç¨‹æ•°ï¼Œæ ¹æ® API çš„ QPS/QPM é™åˆ¶è°ƒæ•´
        :return: (OCRæ–‡æœ¬, tokenä½¿ç”¨é‡æ±‡æ€»)
        """
        lines = []
        page_image_bytes_list = []  # å­˜å‚¨æ‰€æœ‰å¾…å¤„ç†çš„é¡µé¢å›¾åƒ
        
        # æ±‡æ€» token ä½¿ç”¨é‡
        total_token_usage = {
            "prompt_tokens": 0, 
            "completion_tokens": 0, 
            "model": self.model,
            "pages": 0
        }

        # --- é˜¶æ®µ1ï¼šä¸²è¡Œå‡†å¤‡æ‰€æœ‰å›¾åƒï¼ˆCPUå¯†é›†åž‹ï¼Œä¿æŒåœ¨ä¸»çº¿ç¨‹ï¼‰---
        logger.info(f"å¼€å§‹å‡†å¤‡ PDF å›¾åƒï¼ˆä¸²è¡Œï¼‰ï¼Œå…± {self.pdf_path or 'bytes data'}...")
        try:
            if self.pdf_bytes:
                doc = fitz.open(stream=self.pdf_bytes, filetype="pdf")
            else:
                doc = fitz.open(self.pdf_path)
        except Exception as e:
            logger.info(f"âŒ æ‰“å¼€ PDF å¤±è´¥: {e}")
            return f"[é”™è¯¯: æ— æ³•æ‰“å¼€ PDF æ–‡ä»¶ {e}]", total_token_usage

        with doc:
            zoom = self.dpi / 72.0
            mat = fitz.Matrix(zoom, zoom)
            for i, page in enumerate(doc):
                logger.info(f"    æ­£åœ¨æ¸²æŸ“ç¬¬ {i + 1} é¡µ...")
                pix = page.get_pixmap(matrix=mat, alpha=False)
                pil_img = self._pix_to_pil(pix)
                img_bytes = self._pil_to_jpeg_bytes(pil_img, quality=85)
                # å­˜å‚¨å¾…å¤„ç†çš„æ•°æ®
                page_image_bytes_list.append((i + 1, img_bytes))

        logger.info(f"âœ… æ‰€æœ‰é¡µé¢å›¾åƒå‡†å¤‡å®Œæ¯•ï¼Œå…± {len(page_image_bytes_list)} é¡µã€‚")
        total_token_usage["pages"] = len(page_image_bytes_list)

        # --- é˜¶æ®µ2ï¼šå¹¶å‘æ‰§è¡Œ OCRï¼ˆI/Oå¯†é›†åž‹ï¼‰---
        # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥è§£åŒ…å…ƒç»„å¹¶è°ƒç”¨ _ocr_one_image
        # è¿™æ ·æ—¥å¿—æ‰èƒ½æ­£ç¡®æ‰“å°é¡µç 
        def ocr_task(page_data: tuple[int, bytes]) -> tuple[int, str, dict]:
            page_num, img_bytes = page_data
            logger.info(f"\n====== [å¹¶å‘] å¼€å§‹å¤„ç†ç¬¬ {page_num} é¡µ ======")
            logger.info(f">>> å›¾åƒå¤§å°:", len(img_bytes), "bytes", f"(Page {page_num})")

            # _ocr_one_image çŽ°åœ¨è¿”å›ž (text, token_usage)
            text, usage = self._ocr_one_image(img_bytes)

            if not text:
                text = "[OCR å¤±è´¥: æœªè¿”å›žæ–‡æœ¬]"
            logger.info(f"====== [å¹¶å‘] ç¬¬ {page_num} é¡µå¤„ç†å®Œæ¯• ======")
            return (page_num, text, usage)

        # æŒ‰é¡ºåºå­˜å‚¨æœ€ç»ˆç»“æžœ
        page_results = [None] * len(page_image_bytes_list)
        page_usages = []  # å­˜å‚¨æ¯é¡µçš„ token ä½¿ç”¨é‡

        from concurrent.futures import ThreadPoolExecutor, as_completed

        # ä½¿ç”¨ ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            logger.info(f"ðŸš€ å¯åŠ¨çº¿ç¨‹æ±  (max_workers={max_workers})ï¼Œå¼€å§‹å¹¶å‘ OCR...")

            # æäº¤æ‰€æœ‰ä»»åŠ¡
            # æˆ‘ä»¬ä½¿ç”¨ submit è€Œä¸æ˜¯ mapï¼Œä»¥ä¾¿åœ¨æ—¥å¿—ä¸­æ›´å¥½åœ°è·Ÿè¸ª
            future_to_page = {
                executor.submit(ocr_task, page_data): page_data[0]
                for page_data in page_image_bytes_list
            }

            processed_count = 0
            for future in as_completed(future_to_page):
                page_num = future_to_page[future]
                try:
                    page_num_result, text_result, usage = future.result()
                    page_results[page_num_result - 1] = text_result  # æ”¾åˆ°æ­£ç¡®çš„ä½ç½®
                    page_usages.append(usage)
                    processed_count += 1
                    logger.info(
                        f"    (è¿›åº¦: {processed_count}/{len(page_image_bytes_list)}) ç¬¬ {page_num} é¡µç»“æžœå·²èŽ·å–ã€‚")
                except Exception as exc:
                    logger.info(f"âŒ ç¬¬ {page_num} é¡µåœ¨å¹¶å‘å¤„ç†æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {exc}")
                    traceback.print_exc()
                    page_results[page_num - 1] = f"[OCR å¤±è´¥: å‘ç”Ÿå¼‚å¸¸ {exc}]"

        logger.info("âœ… æ‰€æœ‰å¹¶å‘ä»»åŠ¡å®Œæˆã€‚")

        # --- é˜¶æ®µ3ï¼šæ±‡æ€»ç»“æžœ ---
        for i, text in enumerate(page_results):
            lines.append(f"===[PAGE {i + 1}]===\n{text}\n")
        
        # æ±‡æ€» token ä½¿ç”¨é‡
        for usage in page_usages:
            total_token_usage["prompt_tokens"] += usage.get("prompt_tokens", 0)
            total_token_usage["completion_tokens"] += usage.get("completion_tokens", 0)

        raw_result = "\n".join(lines)
        
        # --- é˜¶æ®µ4ï¼šåŽå¤„ç† - æ£€æµ‹å¹¶ä¿®å¤åæ ‡æ ¼å¼é—®é¢˜ ---
        # å¦‚æžœç»“æžœåŒ…å« OCR å¤±è´¥æ ‡è®°æˆ–çœ‹èµ·æ¥åƒåæ ‡æ ¼å¼ï¼Œå°è¯•æå–çº¯æ–‡æœ¬
        if "[OCR å¤±è´¥" in raw_result or self._looks_like_coordinate_format(raw_result):
            logger.info(">>> æ£€æµ‹åˆ° OCR å¤±è´¥æˆ–åæ ‡æ ¼å¼ï¼Œå°è¯•åŽå¤„ç†æå–æ–‡æœ¬...")
            extracted = self._extract_text_from_coordinate_format(raw_result)
            if extracted and len(extracted) > 50:  # è‡³å°‘æå–å‡º 50 å­—ç¬¦çš„æœ‰æ•ˆå†…å®¹
                logger.info(f">>> åæ ‡æ ¼å¼åŽå¤„ç†æˆåŠŸï¼Œæå–æ–‡æœ¬é•¿åº¦: {len(extracted)}")
                return extracted, total_token_usage
            else:
                logger.warning(f">>> åæ ‡æ ¼å¼åŽå¤„ç†å¤±è´¥æˆ–å†…å®¹è¿‡å°‘ï¼Œè¿”å›žåŽŸå§‹ç»“æžœ")
        
        return raw_result, total_token_usage
    
    @staticmethod
    def _looks_like_coordinate_format(text: str) -> bool:
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦çœ‹èµ·æ¥åƒåæ ‡æ ¼å¼"""
        import re
        # åæ ‡æ ¼å¼æ¨¡å¼: å¤šè¡Œ "æ•°å­—,æ•°å­—,æ•°å­—,..." å¼€å¤´
        coord_pattern = re.compile(r'^\d+,\d+,\d+,\d+', re.MULTILINE)
        matches = coord_pattern.findall(text)
        # å¦‚æžœè¶…è¿‡ 3 è¡ŒåŒ¹é…åæ ‡æ ¼å¼ï¼Œè®¤ä¸ºæ˜¯åæ ‡æ ¼å¼
        return len(matches) >= 3

